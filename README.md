## Tensorflow Serving Basic Object Detection Demo

This repo contains a basic set of utilities to build an object detection model and deploy it to tensorflow serving.

This POC uses a micro-service style API front-end and GRPC back end to send images to a tensorflow serving instance hosted on a generic linux machine using paperspace. Tensorflow serving will classify an image using a model trained on the COCO object detection data set and return labels with probabilities of an object being in the image along with (x,y) style coordinates used to calculate the bounding boxes of objects in the image.

### POC Decisions

Some proof of concept decisions I made that may not translate well into a full blown project:

- The detection algorithms are not specifically trained for labelling just things that may be interesting for right of way assets. I wanted to reduce time spent with just training models to setup an API that could receive images and detect classes with realtive accuracy.
- I went through and tweaked data over a few rounds to improve the rate of detection. This is mostly because we would have to do this in real life with a trained model of our own as well. 
- I only created a basic API that would classify one image at a time. I would rather just get something basic working than worry about bulk classification that may be something a direct GRPC client would do.
- I picked a generic linux hosting service using a program that I would setup myself to host a tensorflow model. I didn't want to be pinned to a cloud service just yet, and most of the time these cloud services use the same software under the covers. Reducing the amount of "magic" in an implementation is important for me to see the full picture of what is going on. 
- Given the heavy usage of MS software within the city and reliance on active directory I did not incorporate security into this POC at all. It would've just made things needlessly complicated. It would be interesting to bake up an active directory backed oauth provider for internal applications like this one though. 


### Components

- "API" - can be found in the `api/predict.py` file. This small API is essentially a flask based GRPC proxy that allows a client to use HTTP to send images off for prediction.

- "Client" - An HTML client that will send http requests containing images needing prediction. `api/bulk_request.py` will take directories of processed images and send them to the API produced by `api/predict.py`.

- "Tensorflow Backend" - a tensorflow serving instance that is fairly barebones. Tensorflow serving requires a very specific file format to allow for serving. The `export_to_serving.py` file converts the base model downloaded from google suitable for serving. 

- "Data processor" - There are a set of standalong scripts to process images downloaded from mapillary to make it easier for the object detector to see objects within the image. 

### Architecture

The architecture of the POC is relatively straight forward. 

1. A "client" will make a POST request to the "API"
2. The "API" will establish a connection via GRPC to an instance of tensorflow serving, and send the image to the tf server.
3. The "tensorflow backend" will detect objects, and the bounding boxes of their location returning it to the "API" over the GRPC connection
4. The "API" will draw bounding boxes on the image with probabilities of detection labels then return it to the client.

### Libraries used

- Flask. Great for prototyping and very flexible to make custom things like an http to GRPC proxy.

- GRPC. Required to communicate with tensorflow serving. The compiled "protos" can be found in the `object_detection_compiled_protos`. These are generated by the GRPC client and should not be edited by humans.

- Requests. A nice python HTTP client making it easy to make API requests.

- Pillow. A very handy image processing library in python. I use it to translate images to numpy arrays for tensorflow serving, and for image drawing. It is also used for processing images to make prediction easier.

### API Design

There is currently a single endpoint on the prediction API. It can return JSON or an annotated jpg image. By default it will return an annotated image because this makes for an easier to demo POC. If the `"accept"` header is set to `"application/json"` then all the predicted labels will be returned as a JSON array.

- `/predict/image` 
  - Takes an image as `multipart/form-data`. Currently JPEGs are only accepted.
  - Returns an annotated image or array of `application/json`

### Lessons learned

- Reducing image size and content in images that won't contain detectable content improves the algorithm
- GRPC can be fussy, but is actually pretty great for creating clients to talk directly to tensorflow 
- Flask is a great prototyping tool for python

### Next Steps

- Figuring out auth/authz to make sure resources are used only by specific consumers. It would be interesting to create an active directory backed oauth service. 
- A better defined API style. Using something like the siren hypermedia type would make an API more self documenting. 

### Running the proof of concept

Requirements:

- Python 3.6.5
- Flask
- Requests
- GRPC
- Tensorflow

Starting the flask API:

`FLASK_APP=predict.py flask run`

Flask will connect to tensorflow serving on demand. It does not matter which is started first.

Starting tensorflow serving:

`tensorflow_model_server --port=9000 --model_name=obj_det --model_base_path=/home/paperspace/ssd_mobilenet_v1_coco_2017_11_17`

Send requests for prediction:

1. Place images in the `api/test-data` directory
2. Run `python bulk_request.py`
3. View predicted labels on images in the `api/analyzed-data` directory
